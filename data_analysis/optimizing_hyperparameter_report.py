import learn_all_boyou, logging, sys, random, os, logging, json
import numpy as np

class report_hyper_tunning_results:
    """
    reporting numbers with convenience
    """
    def __init__ (self, logger):
        self.logger     = logger

    def load_data(self, folder_path):
        """
        load the data from every single report file
        :param dict report: the results from classification report file
        """
        self.report = {}
        for root, dirs, files in os.walk(folder_path):
            for filename in files:
                if filename == "classification_report.txt":
                    file_full_path = os.path.join(root, filename)
                    self.logger.info("Start to read file " + file_full_path + " ... ")
                    report_to_read = open(file_full_path)
                    # folder level specified level by level
                    folder_level = root[len(folder_path) + 1::].split('/')
                    # build folder dict
                    self.report[tuple(folder_level)]  = json.load(report_to_read)
                    # self.logger.info(self.report)
                    report_to_read.close()

    def stat_single_run(self, folder_path):
        # if the files does not exist, create an empty one
        if not os.path.exists(folder_path + "/print_info.json"):
            print_info_file = open(folder_path + "/print_info.json", "w")
            json.dump({}, print_info_file, indent = 2)
            print_info_file.close()
        
        # if the print info file exists, read it
        print_info_file = open(folder_path + "/print_info.json", "r")
        print_info = json.load(print_info_file)
        print_info_file.close()

        # This part needs to be modified to suit various different experiment.
        for exp_idx in {param_i[0]:True for param_i in self.report.keys()}.keys():
            for exp_setup in self.report[exp_idx, '1'].keys():
                if exp_setup not in print_info:
                    print_info[exp_setup]           = {}
                    if exp_idx not in print_info[exp_setup]:
                        print_info[exp_setup][exp_idx]  = {}

                print_info[exp_setup][exp_idx]  = \
                    "avg:{0:5f}, std:{1:5f}".format(\
                        np.mean(np.array([self.report[exp_idx, batch_idx]\
                        [exp_setup]['f1_score'] \
                        for batch_idx in {i[1]:True for i in self.report.keys()}.keys() ])),\
                        np.std(np.array([self.report[exp_idx, batch_idx]\
                        [exp_setup]['f1_score'] \
                        for batch_idx in {i[1]:True for i in self.report.keys()}.keys() ])),\
                        )

        self.logger.info("\n" + json.dumps(print_info, indent = 2))

        print_info_file = open(folder_path + "/print_info.json", "w")
        json.dump(print_info, print_info_file, indent = 2)
        print_info_file.close()



if __name__ == "__main__":
    """ 
    logger setup
    """ 
    logger  = logging.getLogger()
    logger.setLevel(logging.DEBUG)

    logger_handler = logging.StreamHandler()
    logger_handler.setFormatter(\
        logging.Formatter('%(asctime)s [%(levelname)s]\
            %(filename)s [%(lineno)d]: %(funcName)s(): %(message)s'))
    logger.addHandler(logger_handler)

    report  = report_hyper_tunning_results(logger)
    report.load_data("optimizing_hyperparameter")
    report.stat_single_run("optimizing_hyperparameter")
    # report.stat_single_run("optimizing_hyperparameter", "Decision Tree")
    # report.stat_single_run("optimizing_hyperparameter", "Random Forest")
    # report.stat_single_run("optimizing_hyperparameter", "AdaBoost")
    # report.stat_single_run("optimizing_hyperparameter", "Naive Bayes")
    # report.stat_single_run("optimizing_hyperparameter", "Neural Net")

