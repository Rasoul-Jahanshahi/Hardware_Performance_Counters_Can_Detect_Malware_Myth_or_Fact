
import logging, json, sys, random, os, shutil
import numpy as np
from sklearn.model_selection import train_test_split
from learn_all_boyou import boyou_learn
from sklearn.metrics import precision_recall_fscore_support
from sklearn.metrics import classification_report
from sklearn.metrics import roc_curve, auc

class boyou_cross_validation(boyou_learn):
    def load_data(self):
        # with open('classification_report.txt', 'r') as input_file:
        #     self.report = json.load(input_file)
        # input_file.close()
        self.report = {}

        self.benign_files  = ['amd_benign_metadata/benign_post_pca_data.txt',\
                        'amd_desktop_metadata/benign_post_pca_data.txt',\
                        'amd_python_benign_metadata/python_benign_post_pca_data.txt'\
                        ]
        self.malware_files = ['amd_malware_metadata/malware_post_pca_data.txt']
        
        def read_bm_list(file_list, padding_list, benign_list=False):
            for files in file_list:
                self.logger.info("Loading " + self.data_path_prefix + files + " ... ")
                with open(self.data_path_prefix + files, 'r') as data_file:
                    json_data = json.load(data_file)
                data_file.close()
                for key in json_data.keys():
                    if benign_list == True:
                        if len(json_data[key]) == 32:
                            padding_list.append(key)
                    else:
                        padding_list.append(key)
                        

        self.benign_list    = []
        read_bm_list(self.benign_files, self.benign_list, benign_list=True)
        self.malware_list   = []
        read_bm_list(self.malware_files, self.malware_list)

        # match the size of benign list and malware list
        matched_size = min(len(self.benign_list), len(self.malware_list))
        self.benign_list    = random.sample(self.benign_list, matched_size)
        self.malware_list   = random.sample(self.malware_list, matched_size)


      
    def train_test_selection(self):
        self.logger.info("number of benignwares " + str(len(self.benign_list)))
        self.logger.info("number of malwares " + str(len(self.malware_list)))
        # first make sure the cross selection between various bms
        benign_train_list   = random.sample(self.benign_list, int(0.9 * len(self.benign_list)))
        malware_train_list  = random.sample(self.malware_list, int(0.9 * len(self.malware_list)))
        benign_test_list    = [elem for elem in self.benign_list if elem not in benign_train_list]
        malware_test_list   = [elem for elem in self.malware_list if elem not in malware_train_list]
        experiment_info                         = {}
        experiment_info['benign_train_list']    = benign_train_list
        experiment_info['malware_train_list']   = malware_train_list
        experiment_info['benign_test_list']     = benign_test_list
        experiment_info['malware_test_list']    = malware_test_list
        with open(self.result_path + "experiment_info.txt", "w") as outfile:
            json.dump(experiment_info, outfile)
        outfile.close()

        self.logger.info('benign_train_list')
        self.logger.info(len(benign_train_list))
        self.logger.info('benign_test_list')
        self.logger.info(len(benign_test_list))
       
        def read_and_vstack(file_list, train_list):
            store_train_data = []
            store_test_data = []
            for files in file_list:
                self.logger.info("Loading " + self.data_path_prefix + files + " ... ")
                with open(self.data_path_prefix + files, 'r') as data_file:
                    json_data = json.load(data_file)

                for bm in json_data.keys():
                    if bm in train_list:
                        for each_sample in json_data[bm]:
                            if store_train_data == []:
                                store_train_data = np.array(each_sample) 
                            else:
                                store_train_data = np.vstack((store_train_data, each_sample))
                    else:
                        for each_sample in json_data[bm]:
                            if store_test_data == []:
                                store_test_data = np.array(each_sample) 
                            else:
                                store_test_data = np.vstack((store_test_data, each_sample))
                data_file.close() 
            return store_train_data, store_test_data

        benign_train_data, benign_test_data     = read_and_vstack(self.benign_files, benign_train_list)
        self.logger.info("benign_train_data.shape")
        self.logger.info(benign_train_data.shape)
        self.logger.info("benign_test_data.shape")
        self.logger.info(benign_test_data.shape)
        malware_train_data, malware_test_data   = read_and_vstack(self.malware_files, malware_train_list)

        self.logger.info("malware_train_data.shape")
        self.logger.info(malware_train_data.shape)
        self.logger.info("malware_test_data.shape")
        self.logger.info(malware_test_data.shape)
        # match bias within data set
        half_train_size     = min(len(benign_train_data), len(malware_train_data))
        half_test_size      = min(len(benign_test_data), len(malware_test_data))
        self.logger.info(half_train_size)
        self.logger.info(half_test_size)

        self.X_train        = np.vstack((\
                                random.sample(benign_train_data, half_train_size),\
                                random.sample(malware_train_data, half_train_size)\
                                ))
        self.X_test         = np.vstack((\
                                random.sample(benign_test_data, half_test_size),\
                                random.sample(malware_test_data, half_test_size)\
                                ))

        self.y_train   = np.concatenate((np.ones(half_train_size), np.zeros(half_train_size)))
        self.y_test    = np.concatenate((np.ones(half_test_size), np.zeros(half_test_size)))
        self.logger.info("train Size " + str(len(self.y_train)))
        self.logger.info("test Size " + str(len(self.y_test)))

    def experiment_1(self):
        # if os.path.isdir(self.result_path):
        #     shutil.rmtree(self.result_path)
        # os.mkdir(self.result_path) 

        self.load_data()
        self.train_test_selection()
        self.setup_classifiers()
        self.report     = {}
            
        for names, clf in zip(self.names, self.classifiers):
            self.logger.info(names + " in process ....")
            clf.fit(self.X_train, self.y_train)

            clf_info = {}
            if os.path.isfile(self.result_path + "properties.txt"):
                with open(self.result_path + "properties.txt", "r") as outfile:
                    clf_info = json.load(outfile)
                outfile.close()

            if names is "AdaBoost":
                # dump the list of estimators
                clf_info["AdaBoost"] = {}
                clf_info["AdaBoost"]["estimators"] = len(clf.estimators_)
                self.logger.info(clf.estimators_)
                self.logger.info(clf.estimator_weights_)
                self.logger.info(clf.estimator_errors_)
            elif names is "Decision Tree":
                clf_info["Decision Tree"] = {}
                clf_info["Decision Tree"]["max_features"] = clf.max_features_
            elif names is "Random Forest":
                clf_info["Random Forest"] = {}
                clf_info["Random Forest"]["estimators"] = len(clf.estimators_)

            with open(self.result_path + "properties.txt", "w") as outfile:
                json.dump(clf_info, outfile)
            outfile.close()

            self.prediction  = clf.predict(self.X_test)
            self.predict_proba  = clf.predict_proba(self.X_test)
            self.text_class_report(names)
            self.roc_curve_report(names)
            self.logger.info(names + " testing completed!")

if __name__ == "__main__":
    global logger    
    logger  = logging.getLogger()
    logger.setLevel(logging.DEBUG)

    logger_handler = logging.StreamHandler()
    logger_handler.setFormatter(\
        logging.Formatter(\
        '%(asctime)s [%(levelname)s] %(filename)s [%(lineno)d]: %(funcName)s(): %(message)s'))
    logger.addHandler(logger_handler)

    learn1 = boyou_cross_validation(logger,\
        data_path_prefix='../amd_data/')

    learn1.result_path = sys.argv[1] + '/'
    learn1.logger.info('Result is in folder ' + learn1.result_path)
    learn1.experiment_1()
